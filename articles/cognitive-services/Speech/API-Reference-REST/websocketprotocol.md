---
title: Протокол распознавания речи WebSocket Майкрософт | Документация Майкрософт
description: Документация по протоколу службы распознавания речи на основе WebSockets
services: cognitive-services
author: zhouwangzw
manager: wolfma
ms.service: cognitive-services
ms.component: bing-speech
ms.topic: article
ms.date: 09/15/2017
ms.author: zhouwang
ms.openlocfilehash: 17954536e8bdb49c09204c2e522586b79cb1bef5
ms.sourcegitcommit: 95d9a6acf29405a533db943b1688612980374272
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/23/2018
ms.locfileid: "35380636"
---
# <a name="speech-service-websocket-protocol"></a>Протокол службы распознавания речи WebSocket

  Служба распознавания речи — это облачная платформа, в которой реализованы самые передовые алгоритмы, доступные для преобразования разговорной речи в текст. Протокол службы распознавания речи определяет [подключение](#connection-establishment) между клиентскими приложениями, службой и сообщениями распознавания речи, которыми обмениваются контрагенты ([сообщения, инициированные клиентом](#client-originated-messages), и [сообщения, инициированные службой](#service-originated-messages)). Кроме того, описаны [сообщения телеметрии](#telemetry-schema) и [обработка ошибок](#error-handling).

## <a name="connection-establishment"></a>Установление соединения

Протокол службы распознавания речи соответствует стандартной спецификации WebSocket [IETF RFC 6455](https://tools.ietf.org/html/rfc6455). Подключение WebSocket начинается как HTTP-запрос, содержащий заголовки HTTP, которые указывают на желание клиента обновить соединение с WebSocket вместо использования семантики HTTP. Сервер указывает на свою готовность участвовать в соединении WebSocket, возвращая ответ HTTP `101 Switching Protocols`. После обмена этим подтверждением как клиент, так и служба поддерживают сокет в открытом состоянии и начинают использовать протокол на основе сообщений для отправки и получения информации.

Чтобы начать подтверждение WebSocket, клиентское приложение отправляет в службу запрос HTTPS GET. Он содержит стандартные заголовки обновления WebSocket, а также другие заголовки, которые относятся к речи.

```HTTP
GET /speech/recognition/interactive/cognitiveservices/v1 HTTP/1.1
Host: speech.platform.bing.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
Sec-WebSocket-Version: 13
Authorization: t=EwCIAgALBAAUWkziSCJKS1VkhugDegv7L0eAAJqBYKKTzpPZOeGk7RfZmdBhYY28jl&p=
X-ConnectionId: A140CAF92F71469FA41C72C7B5849253
Origin: https://speech.platform.bing.com
```

Эта служба возвращает следующее:

```HTTP
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: upgrade
Sec-WebSocket-Key: 2PTTXbeeBXlrrUNsY15n01d/Pcc=
Set-Cookie: SpeechServiceToken=AAAAABAAWTC8ncb8COL; expires=Wed, 17 Aug 2016 15:39:06 GMT; domain=bing.com; path="/"
Date: Wed, 17 Aug 2016 15:03:52 GMT
```

Для всех запросов речи требуется шифрование [TLS](https://en.wikipedia.org/wiki/Transport_Layer_Security). Использование незашифрованных речевых запросов не поддерживается. Поддерживаются следующие версии TLS.

* TLS 1.2

### <a name="connection-identifier"></a>Идентификатор подключения

Службе распознавания речи требуется, чтобы все клиенты включали уникальный идентификатор для идентификации соединения. Клиенты *должны* включать заголовок *X-ConnectionId*, когда они начинают подтверждение WebSocket. Заголовок *X ConnectionId* должен быть значением [глобального уникального идентификатора](https://en.wikipedia.org/wiki/Universally_unique_identifier) (UUID). Запросы на обновление WebSocket, которые не содержат *X-ConnectionId*, не указывают значение для заголовка *X-ConnectionId* или не содержат действительное значение UUID, отклоняются службой с помощью ответа HTTP `400 Bad Request`.

### <a name="authorization"></a>Авторизация

В дополнение к стандартным заголовкам подтверждения WebSocket для запросов речи требуется заголовок *Authorization*. Запросы на подключение без этого заголовка отклоняются службой с помощью ответа HTTP `403 Forbidden`.

Заголовок *Authorization* должен содержать маркер доступа к JSON Web Token (JWT).

Для получения информации о том, как подписаться и получить ключи API, которые используются для получения действительных маркеров доступа JWT, см. страницу [подписки Cognitive Services](https://azure.microsoft.com/try/cognitive-services/).

Ключ API передается службе токенов. Например: 

``` HTTP
POST https://api.cognitive.microsoft.com/sts/v1.0/issueToken
Content-Length: 0
```

Для доступа к токенам требуется следующие данные заголовка.

| ИМЯ | Формат | ОПИСАНИЕ |
|----|----|----|
| Ocp-Apim-Subscription-Key | ASCII | Ваш ключ подписки |

Служба токенов возвращает маркер доступа JWT в виде `text/plain`. Затем JWT передается в качестве `Base64 access_token` к подтверждению как заголовок *Authorization* с префиксом в виде строки `Bearer`. Например: 

`Authorization: Bearer [Base64 access_token]`

### <a name="cookies"></a>Файлы cookie

Клиенты *должны* поддерживать файлы cookie HTTP, как указано в [RFC 6265](https://tools.ietf.org/html/rfc6265).

### <a name="http-redirection"></a>Перенаправление HTTP

Клиенты *должны* поддерживать стандартные механизмы перенаправления, указанные в спецификации протокола [HTTP](http://www.w3.org/Protocols/rfc2616/rfc2616.html).

### <a name="speech-endpoints"></a>Конечные точки преобразования текста в речь

Клиенты *должны* использовать соответствующую конечную точку службы преобразования текста в речь. Конечная точка основана на режиме распознавания и языке. В таблице показаны некоторые примеры.

| Mode | Путь | URI службы |
| -----|-----|-----|
| Interactive | /speech/recognition/interactive/cognitiveservices/v1 |https://speech.platform.bing.com/speech/recognition/interactive/cognitiveservices/v1?language=pt-BR |
| Беседа | /speech/recognition/conversation/cognitiveservices/v1 |https://speech.platform.bing.com/speech/recognition/conversation/cognitiveservices/v1?language=en-US |
| Диктовка | /speech/recognition/dictation/cognitiveservices/v1 |https://speech.platform.bing.com/speech/recognition/dictation/cognitiveservices/v1?language=fr-FR |

Дополнительные сведения см. в разделе [URI службы](../GetStarted/GetStartedREST.md#service-uri).

### <a name="report-connection-problems"></a>Проблемы с подключением

Клиенты должны немедленно сообщать обо всех возникающих проблемах при подключении. Протокол для сообщения о неудачных соединениях описан в разделе [Телеметрия сбоя подключения](#connection-failure-telemetry).

### <a name="connection-duration-limitations"></a>Ограничения продолжительности подключения

По сравнению с типичными HTTP-соединениями веб-службы соединения WebSocket продолжаются *длительное время*. Служба распознавания речи ограничивает продолжительность подключений WebSocket со службой:

 * Максимальная продолжительность любого активного подключения WebSocket составляет 10 минут. Подключение активно, если служба или клиент отправляют по нему сообщения WebSocket. Служба прекращает подключение без предупреждения, когда предел достигнут. Клиенты должны разрабатывать пользовательские сценарии, которые не требуют, чтобы соединение оставалось активным в течение или около максимального срока службы соединения.

 * Максимальная продолжительность любого неактивного подключения WebSocket составляет 180 секунд. Подключение неактивно, если через него ни служба, ни клиент не отправили сообщение WebSocket. После достижения максимального неактивного времени жизни служба прекращает неактивное соединение WebSocket.

## <a name="message-types"></a>Типы сообщений

После установления соединения WebSocket между клиентом и службой они могут отправлять сообщения. В этом разделе описывается формат этих сообщений WebSocket.

[IETF RFC 6455](https://tools.ietf.org/html/rfc6455) указывает, что сообщения WebSocket могут передавать данные с использованием либо текстового, либо двоичного кодирования. В этих двух кодировках используются разные форматы. Каждый формат оптимизирован для эффективного кодирования, передачи и декодирования полезных данных сообщения.

### <a name="text-websocket-messages"></a>Текстовые сообщения WebSocket

Текстовые сообщения WebSocket содержат полезные данные в виде текстовой информации, состоящей из раздела заголовков и текста, разделенных знакомой парой новых строк с двойным возвратом каретки, используемой для сообщений HTTP. Как и HTTP-сообщения, текстовые сообщения WebSocket указывают заголовки в формате *имя: значение*, разделенные парой новой строки с однократным возвратом каретки. Любой текст, содержащийся в текстовом сообщении WebSocket, *должен* использовать [кодировку UTF-8](https://tools.ietf.org/html/rfc3629).

В текстовых сообщениях WebSocket должен указываться путь сообщения в заголовке *Path*. Значение этого заголовка должно быть одним из типов сообщений речевого протокола, определенных ниже в этом документе.

### <a name="binary-websocket-messages"></a>Двоичные сообщения WebSocket

Двоичные сообщения WebSocket содержат двоичные полезные данные. В протоколе службы распознавания речи аудио передается и принимается от службы с помощью двоичных сообщений WebSocket. Все остальные сообщения представляют собой текстовые сообщения WebSocket. 

Как и текстовые сообщения WebSocket, двоичные сообщения WebSocket состоят из раздела заголовка и текста. Первые 2 байта двоичного сообщения WebSocket указывают в [обратном порядке байтов](https://en.wikipedia.org/wiki/Endianness) 16-разрядный целочисленный размер секции заголовка. Минимальный размер раздела заголовка составляет 0 байт. Максимальный размер составляет 8192 байта. Текст в заголовках двоичных сообщений WebSocket *должен* использовать кодировку [US-ASCII](https://tools.ietf.org/html/rfc20).

Заголовки в двоичном сообщении WebSocket кодируются в том же формате, что и в текстовых сообщениях WebSocket. Формат *имя: значение* разделяется парой новой строки с одним возвратом каретки. В двоичных сообщениях WebSocket должен указываться путь сообщения в заголовке *Path*. Значение этого заголовка должно быть одним из типов сообщений речевого протокола, определенных ниже в этом документе.

Как текстовые, так и двоичные сообщения WebSocket используются в протоколе службы распознавания речи. 

## <a name="client-originated-messages"></a>Сообщения, инициированные клиентом

После установки подключения и клиент, и служба могут начать отправлять сообщения. В этом разделе описывается формат и полезные данные сообщений, отправляемых клиентскими приложениями в службу распознавания речи. В разделе [Сообщения, инициированные службой](#service-originated-messages), представлены сообщения, которые появляются в службе распознавания речи и отправляются в клиентские приложения.

Основными сообщениями, отправленными клиентом службам, являются сообщения `speech.config`, `audio` и `telemetry`. Прежде чем мы подробно рассмотрим каждое сообщение, далее описаны общие необходимые заголовки для всех этих сообщений.

### <a name="required-message-headers"></a>Требуемые заголовки сообщений

Следующие заголовки необходимы для всех сообщений, инициированных клиентом.

| Заголовок | Значение |
|----|----|
| Путь | Путь сообщений, указанный в этом документе |
| X-RequestId | UUID в формате "без тире" |
| X-Timestamp | Клиентская метка времени UTC в формате ISO 8601 |

#### <a name="x-requestid-header"></a>Заголовок X-RequestId

Запросы, инициированные клиентом, уникально идентифицируются заголовком сообщения *X-RequestId*. Этот заголовок необходим для всех сообщений, инициированных клиентом. Значение заголовка *X-RequestId* должно быть в формате UUID в форме "без тире", например *123e4567e89b12d3a456426655440000*. Его *нельзя* представлять в канонической форме *123e4567-e89b-12d3-a456-426655440000*. Запросы без заголовка *X-RequestId* или с заголовком, использующим неправильный формат UUID, приводят к прерыванию подключения WebSocket.

#### <a name="x-timestamp-header"></a>Заголовок X-Timestamp

Каждое сообщение, отправленное в службу клиентским приложением, *должно* содержать заголовок *X-Timestamp*. Значение для этого заголовка — это время, когда клиент отправляет сообщение. Запросы без заголовка *X-Timestamp* или с заголовком, использующим неправильный формат, приводят к прерыванию подключения WebSocket.

Значение заголовка *X-Timestamp* должно иметь форму 'yyyy'-'MM'-'dd'T'HH':'mm':'ss'.'fffffffZ', где 'fffffff' — это доли секунды. Например, '12,5'означает '12+5/10 секунд' и '12,526 'означает '12+526/1000 секунд'. Этот формат соответствует [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) и, в отличие от стандартного заголовка HTTP *Date*, может обеспечить разрешение в миллисекундах. Клиентские приложения могут округлять метки времени до ближайшей миллисекунды. Клиентским приложениям необходимо убедиться, что часы устройства точно отслеживают время с помощью сервера [Network Time Protocol (NTP)](https://en.wikipedia.org/wiki/Network_Time_Protocol).

### <a name="message-speechconfig"></a>Сообщение `speech.config`

Служба распознавания речи должна знать характеристики вашего приложения, чтобы обеспечить наилучшее распознавание речи. Данные требуемых характеристик включают в себя информацию об устройстве и ОС, которые поддерживают ваше приложение. Предоставьте эту информацию в сообщении `speech.config`.

Клиенты *должны* отправить сообщение `speech.config` сразу после установки подключения к службе распознавания речи и перед отправкой любых сообщений `audio`. Вам необходимо отправить сообщение `speech.config` только один раз за подключение.

| Поле | ОПИСАНИЕ |
|----|----|
| Кодирование сообщений WebSocket | текст |
| Текст | Полезные данные в качестве структуры JSON |

#### <a name="required-message-headers"></a>Требуемые заголовки сообщений

| Имя заголовка | Значение |
|----|----|
| Путь | `speech.config` |
| X-Timestamp | Клиентская метка времени UTC в формате ISO 8601 |
| Content-Type | application/json; charset=utf-8 |

Как и все сообщения, инициированные клиентом в протоколе службы распознавания речи, сообщение `speech.config` *должно* содержать заголовок *X-Timestamp*, который записывает время в формате UTC клиента, когда сообщение было отправлено в службу. Сообщению `speech.config` *не требуется* заголовок *X-RequestId*, потому что это сообщение не связано с конкретным запросом речи.

#### <a name="message-payload"></a>Полезные данные сообщения
Полезные данные сообщения `speech.config` представляют собой структуру JSON, которая содержит информацию о приложении. В следующем примере показаны эти сведения. Информация контекста клиента и устройства включена в элемент *context* структуры JSON. 

```JSON
{
  "context": {
    "system": {
      "version": "2.0.12341",
    },
    "os": {
      "platform": "Linux",
      "name": "Debian",
      "version": "2.14324324"
    },
    "device": {
      "manufacturer": "Contoso",
      "model": "Fabrikan",
      "version": "7.341"
      }
    },
  }
}
```

##### <a name="system-element"></a>Элемент системы

Элемент system.version сообщения `speech.config` содержит версию программного обеспечения пакета SDK речи, используемого клиентским приложением или устройством. Значение указывается в виде *major.minor.build.branch*. Вы можете опустить компонент *branch*, если он не применим.

##### <a name="os-element"></a>Элемент ОС

| Поле | ОПИСАНИЕ | Использование |
|-|-|-|
| os.platform | Платформа ОС, на которой размещено приложение, например Windows, Android, iOS или Linux |Обязательно |
| os.name | Название операционной системы, например Debian или Windows 10 | Обязательно |
| os.version | Версия операционной системы в виде *major.minor.build.branch* | Обязательно |

##### <a name="device-element"></a>Элемент устройства

| Поле | ОПИСАНИЕ | Использование |
|-|-|-|
| device.manufacturer | Изготовитель оборудования устройства | Обязательно |
| device.model | Модель устройства | Обязательно |
| device.version | Версия программного обеспечения устройства, предоставленная производителем устройства. В этом значении указывается версия устройства, которую может отслеживать производитель. | Обязательно |

### <a name="message-audio"></a>Сообщение `audio`

Клиентские приложения с поддержкой речи отправляют аудио в службу распознавания речи путем преобразования аудиопотока в серию звуковых блоков. Каждый блок аудио содержит сегмент аудио с речью, который должен быть транскрибирован службой. Максимальный размер одного блока аудио составляет 8192 байта. Сообщения аудиопотока — это *двоичные сообщения WebSocket*.

Клиенты используют сообщение `audio` для отправки блоков аудио в службу. Клиенты считывают звук с микрофона блоками и отправляют эти блоки в службу распознавания речи для транскрибирования. Первое сообщение `audio` должно содержать хорошо сформированный заголовок, который правильно указывает, что аудио соответствует одному из форматов кодировки, поддерживаемых службой. Дополнительные сообщения `audio` содержат только данные двоичного аудиопотока, считанные с микрофона.

Клиенты могут при необходимости отправить сообщение `audio` с текстом нулевой длины. Это сообщение информирует службу о том, что клиент знает, что пользователь перестал говорить, фраза завершена, а микрофон выключен.

Служба распознавания речи использует первое сообщение `audio`, которое содержит уникальный идентификатор запроса, чтобы сигнализировать о начале нового цикла запроса и ответа или *повтора*. После того как служба получит сообщение `audio` с новым идентификатором запроса, она отбрасывает любые сообщения в очереди или неотправленные, которые связаны с любым предыдущим циклом.

| Поле | ОПИСАНИЕ |
|-------------|----------------|
| Кодирование сообщений WebSocket | Binary |
| Текст | Двоичные данные для блока аудио. Максимальный размер составляет 8192 байта. |

#### <a name="required-message-headers"></a>Требуемые заголовки сообщений

Ниже приведены обязательные заголовки для всех сообщений `audio`.

| Заголовок         |  Значение     |
| ------------- | ---------------- |
| Путь | `audio` |
| X-RequestId | UUID в формате "без тире" |
| X-Timestamp | Клиентская метка времени UTC в формате ISO 8601 |
| Content-Type | Тип содержимого аудио. Тип должен быть либо *audio/x-wav* (PCM), либо *audio/silk* (SILK). |

#### <a name="supported-audio-encodings"></a>Поддерживаемые кодировки аудио

В этом разделе описываются аудиокодеки, поддерживаемые службой распознавания речи.

##### <a name="pcm"></a>PCM

Служба распознавания речи принимает звук в формате PCM (импульсно-кодовая модуляция). Аудио отправляется службе в формате [WAV](https://en.wikipedia.org/wiki/WAV), поэтому первый блок аудио *должен* содержать допустимый заголовок [Resource Interchange File Format](https://en.wikipedia.org/wiki/Resource_Interchange_File_Format) (RIFF). Если клиент инициирует повтор звукового блока, который *не* включает в себя допустимый заголовок RIFF, служба отклоняет запрос и завершает подключение WebSocket.

Аудио в формате PCM *должно* иметь частоту дискретизации 16 кГц с 16 бит на семпл и один канал (*riff-16khz-16bit-mono-pcm*). Служба распознавания речи не поддерживает стереофонические аудиопотоки и отклоняет аудиопотоки, которые не используют указанную скорость передачи данных, частоту дискретизации или количество каналов.

##### <a name="opus"></a>Opus

Opus — это открытый, бесплатный, широкоуниверсальный аудиокодек. Служба распознавания речи поддерживает Opus с постоянной скоростью `32000` или `16000`. В настоящее время поддерживается только контейнер `OGG` для Opus, который задается типом mime `audio/ogg`.

Чтобы использовать Opus, измените пример [JavaScript](https://github.com/Azure-Samples/SpeechToText-WebSockets-Javascript/blob/master/samples/browser/Sample.html#L101) и измените метод `RecognizerSetup` для возврата.

```javascript
return SDK.CreateRecognizerWithCustomAudioSource(
            recognizerConfig,
            authentication,
            new SDK.MicAudioSource(
                     new SDK.OpusRecorder(
                     {
                         mimeType: "audio/ogg",
                         bitsPerSecond: 32000
                     }
              )
          ));
```

#### <a name="detect-end-of-speech"></a>Обнаружение окончания речи

Люди явно не сигнализируют, когда они закончат говорить. Любое приложение, принимающее речь как входные данные, имеет два варианта обработки конца речи в аудиопотоке: обнаружение конца речи и обнаружение конца речи клиента. Из этих двух вариантов обнаружение конца речи службой, как правило, обеспечивает лучшее взаимодействие пользователя.

##### <a name="service-end-of-speech-detection"></a>Обнаружение окончания речи службой

Чтобы создать идеальную громкую связь, приложения позволяют службе обнаруживать, когда пользователь закончил говорить. Клиенты отправляют аудио с микрофона в виде блоков *аудио*, пока служба не обнаружит тишину и не ответит сообщением `speech.endDetected`.

##### <a name="client-end-of-speech-detection"></a>Обнаружение службой окончания речи

Клиентские приложения, которые позволяют пользователю каким-либо образом сигнализировать конец речи, также могут передать службе этот сигнал. Например, клиентское приложение может иметь кнопку "Стоп" или "Отключить звук", которую пользователь может нажать. Чтобы сигнализировать о конце речи, клиентские приложения отправляют сообщение с блоком *аудио* нулевой длины. Служба распознавания речи интерпретирует это сообщение как конец входящего аудиопотока.

### <a name="message-telemetry"></a>Сообщение `telemetry`

Клиентские приложения *должны* подтвердить конец каждого цикла, отправив телеметрию о цикле в службу распознавания речи. Подтверждение завершения цикла позволяет службе распознавания речи обеспечить возможность того, что все сообщения, необходимые для завершения запроса и его ответа, были правильно получены клиентом. Подтверждение завершения цикла также позволяет службе убедиться, что клиентские приложения работают, как ожидалось. Эти сведения важны, если вам нужна помощь в устранении неполадок работы приложения с поддержкой речи.

Клиенты должны подтвердить конец цикла, отправив сообщение `telemetry` вскоре после получения сообщения `turn.end`. Клиенты должны как можно скорее подтвердить `turn.end`. Если клиентское приложение не может подтвердить конец цикла, служба преобразования речи может завершить соединение ошибкой. Клиенты должны отправлять только одно сообщение `telemetry` для каждого запроса и ответа, идентифицированного значением *X-RequestId*.

| Поле | ОПИСАНИЕ |
| ------------- | ---------------- |
| Кодирование сообщений WebSocket | текст |
| Путь | `telemetry` |
| X-Timestamp | Клиентская метка времени UTC в формате ISO 8601 |
| Content-Type | `application/json` |
| Текст | Структура JSON, которая содержит информацию о клиенте |

Схема для текста сообщения `telemetry` определена в разделе [схемы телеметрии](#telemetry-schema).

#### <a name="telemetry-for-interrupted-connections"></a>Телеметрия для прерванных подключений

Если по какой-либо причине сетевое подключение не работает, а клиент *не* получает сообщение `turn.end` от службы, клиент отправляет сообщение `telemetry`. Это сообщение описывает неудавшийся запрос при следующем подключении клиента к службе. Клиентам не нужно немедленно пытаться подключиться, чтобы отправить сообщение `telemetry`. Сообщение может быть помещено в буфер клиента и отправлено в следующем подключении, запрашиваемом пользователем. Сообщение `telemetry` для неудачного запроса *должно* использовать значение *X-RequestId* из неудачного запроса. Оно может быть отправлено службе, как только будет установлено соединение, не дожидаясь отправки или получения других сообщений.

## <a name="service-originated-messages"></a>Сообщения, инициированные службой

В этом разделе описываются сообщения, которые появляются в службе распознавания речи и отправляются клиенту. Служба распознавания речи поддерживает реестр возможностей клиента и создает сообщения, необходимые каждому клиенту, поэтому не все клиенты получают все сообщения, которые описаны здесь. Для краткости сообщения ссылаются на значение заголовка *Path*. Например, мы ссылаемся на текстовое сообщение WebSocket со значением *Path* `speech.hypothesis` в качестве сообщения speech.hypothesis.

### <a name="message-speechstartdetected"></a>Сообщение `speech.startDetected`

Сообщение `speech.startDetected` указывает, что служба распознавания речи обнаружила речь в аудиопотоке.

| Поле | ОПИСАНИЕ |
| ------------- | ---------------- |
| Кодирование сообщений WebSocket | текст |
| Путь | `speech.startDetected` |
| Content-Type | application/json; charset=utf-8 |
| Текст | Структура JSON, которая содержит информацию об условиях, когда началось обнаружение речи. Поле *Offset* в этой структуре определяет смещение (в единицах 100 наносекунд), когда речь была обнаружена в аудиопотоке относительно его начала. |

#### <a name="sample-message"></a>Пример сообщения

```HTML
Path: speech.startDetected
Content-Type: application/json; charset=utf-8
X-RequestId: 123e4567e89b12d3a456426655440000

{
  "Offset": 100000
}
```

### <a name="message-speechhypothesis"></a>Сообщение `speech.hypothesis`

Во время распознавания речи служба периодически создает гипотезы об узнаваемых словах. Служба распознавания отправляет эти гипотезы клиенту примерно каждые 300 миллисекунд. `speech.hypothesis` подходит *только* для улучшения восприятия речи пользователя. Вы не должны полагаться на содержимое или точность текста в этих сообщениях.

 Сообщение `speech.hypothesis` применимо к тем клиентам, у которых есть возможность отображения текста и которые хотят предоставить обратную связь в режиме реального времени для распознавания в процессе речи человека.

| Поле | ОПИСАНИЕ |
| ------------- | ---------------- |
| Кодирование сообщений WebSocket | текст |
| Путь | `speech.hypothesis` |
| X-RequestId | UUID в формате "без тире" |
| Content-Type | приложение/json |
| Текст | Структура JSON предположения речи |

#### <a name="sample-message"></a>Пример сообщения

```HTML
Path: speech.hypothesis
Content-Type: application/json; charset=utf-8
X-RequestId: 123e4567e89b12d3a456426655440000

{
  "Text": "this is a speech hypothesis",
  "Offset": 0,
  "Duration": 23600000
}
```

Элемент *Offset* указывает смещение (в единицах 100 наносекунд), когда фраза была распознана относительно начала аудиопотока.

Элемент *Duration* указывает продолжительность (в единицах 100 наносекунд) этой речевой фразы.

Клиенты не должны делать никаких предположений о частоте, времени или тексте, содержащемся в предположении речи, или о согласованности текста в любых двух предположениях. Предположения — это всего лишь моментальные снимки в процессе транскрибирования в службе. Они не представляют собой стабильное накопление транскрибирования. Например, первое предположение может содержать слова "fine fun", а второе может содержать слова "find funny". Служба распознавания речи не выполняет никакой пост-обработки (например, капитализации, пунктуации) текста в предположении речи.

### <a name="message-speechphrase"></a>Сообщение `speech.phrase`

Когда служба определяет, что у нее достаточно информации для получения результата распознавания, который не изменится, служба выдает сообщение `speech.phrase`. Служба выдает эти результаты после того, как обнаруживает, что пользователь закончил предложение или фразу.

| Поле | ОПИСАНИЕ |
| ------------- | ---------------- |
| Кодирование сообщений WebSocket | текст |
| Путь | `speech.phrase` |
| Content-Type | приложение/json |
| Текст | Структура JSON речевой фразы |

Структура JSON речевой фразы включает в себя следующие поля: `RecognitionStatus`, `DisplayText`, `Offset` и `Duration`. Дополнительные сведения об этих полях см. в разделе [Ответы транскрибирования](../concepts.md#transcription-responses).

#### <a name="sample-message"></a>Пример сообщения

```HTML
Path: speech.phrase
Content-Type: application/json; charset=utf-8
X-RequestId: 123e4567e89b12d3a456426655440000

{
  "RecognitionStatus": "Success",
  "DisplayText": "Remind me to buy 5 pencils.",
  "Offset": 0,
  "Duration": 12300000
}
```

### <a name="message-speechenddetected"></a>Сообщение `speech.endDetected`

Сообщение `speech.endDetected` указывает, что клиентское приложение должно прекратить передачу аудио в службу.

| Поле | ОПИСАНИЕ |
| ------------- | ---------------- |
| Кодирование сообщений WebSocket | текст |
| Путь | `speech.endDetected` |
| Текст | Структура JSON, которая содержит смещение при обнаружении конца речи. Смещение представлено в единицах 100 наносекунд, смещенных от начала аудио, которое используется для распознавания. |
| Content-Type | application/json; charset=utf-8 |

#### <a name="sample-message"></a>Пример сообщения

```HTML
Path: speech.endDetected
Content-Type: application/json; charset=utf-8
X-RequestId: 123e4567e89b12d3a456426655440000

{
  "Offset": 0
}
```

Элемент *Offset* указывает смещение (в единицах 100 наносекунд), когда фраза была распознана относительно начала аудиопотока.

### <a name="message-turnstart"></a>Сообщение `turn.start`

`turn.start` обозначает начало цикла с точки зрения службы. Сообщение `turn.start` всегда является первым ответным сообщением, которое вы получаете для любого запроса. Если вы не получили сообщение `turn.start`, скорее всего состояние подключения к службе недействительно.

| Поле | ОПИСАНИЕ |
| ------------- | ---------------- |
| Кодирование сообщений WebSocket | текст |
| Путь | `turn.start` |
| Content-Type | application/json; charset=utf-8 |
| Текст | Структура файла JSON |

#### <a name="sample-message"></a>Пример сообщения

```HTML
Path: turn.start
Content-Type: application/json; charset=utf-8
X-RequestId: 123e4567e89b12d3a456426655440000

{
  "context": {
    "serviceTag": "7B33613B91714B32817815DC89633AFA"
  }
}
```

Текст сообщения `turn.start` представляет собой структуру JSON, содержащую контекст для начала цикла. Элемент *контекста* содержит свойство *serviceTag*. Это свойство указывает значение тега, которое служба связывает с циклом. Это значение может быть использовано Майкрософт, если вам нужна помощь в устранении неполадок в вашем приложении.

### <a name="message-turnend"></a>Сообщение `turn.end`

`turn.end` обозначает конец цикла с точки зрения службы. Сообщение `turn.end` всегда является последним ответным сообщением, которое вы получаете для любого запроса. Клиенты могут использовать получение этого сообщения в качестве сигнала для действий по очистке и перехода в состояние ожидания. Если вы не получили сообщение `turn.end`, скорее всего состояние подключения к службе недействительно. В этих случаях прервите существующее соединение со службой и заново установите его.

| Поле | ОПИСАНИЕ |
| ------------- | ---------------- |
| Кодирование сообщений WebSocket | текст |
| Путь | `turn.end` |
| Текст | None |

#### <a name="sample-message"></a>Пример сообщения

```HTML
Path: turn.end
X-RequestId: 123e4567e89b12d3a456426655440000
```

## <a name="telemetry-schema"></a>Схема телеметрии

Текст сообщения *телеметрии* представляет собой структуру JSON, которая содержит информацию клиента о цикле или попытке подключения. Структура состоит из меток времени клиента, которые записываются при возникновении событий клиента. Каждая метка времени должна быть в формате ISO 8601, как описано в разделе "Заголовок X-Timestamp". Сообщения *телеметрии*, которые не указывают все необходимые поля в структуре JSON или не используют правильный формат метки времени, могут привести к прекращению соединения с клиентом. Клиенты *должны* предоставлять допустимые значения для всех обязательных полей. Клиенты *должны* задавать значения для необязательных полей, когда это необходимо. Значения, показанные в примерах в этом разделе, приведены только для иллюстрации.

Схема телеметрии разделена на следующие части: полученные метки времени и метрики сообщения. Формат и использование каждой части указаны в следующих разделах.

### <a name="received-message-time-stamps"></a>Метки времени полученных сообщений

Клиенты должны включать значения времени приема для всех сообщений, которые они получают после успешного подключения к службе. Эти значения должны записывать время, когда клиент *получил* каждое сообщение из сети. Значение не должно записываться в другое время. Например, клиент не должен записывать время, когда он *действовал* в сообщении. Полученные метки времени сообщения задаются в массиве пар *имя:значение*. Имя пары указывает значение *Path* сообщения. Значение пары указывает время клиента, когда сообщение было получено. Или, если получено несколько сообщений с указанным именем, значение пары — это массив меток времени, которые указывают, когда были получены эти сообщения.

```JSON
  "ReceivedMessages": [
    { "speech.hypothesis": [ "2016-08-16T15:03:48.172Z", "2016-08-16T15:03:48.331Z", "2016-08-16T15:03:48.881Z" ] },
    { "speech.endDetected": "2016-08-16T15:03:49.721Z" },
    { "speech.phrase": "2016-08-16T15:03:50.001Z" },
    { "turn.end": "2016-08-16T15:03:51.021Z" }
  ]
```

Клиенты *должны* подтвердить получение всех сообщений, отправленных службой, включив метки времени для этих сообщений в тексте JSON. Если клиент не может подтвердить получение сообщения, служба может прекратить соединение.

### <a name="metrics"></a>Метрики

Клиенты должны включать информацию о событиях, которые произошли в течение срока действия запроса. Поддерживаются следующие метрики: `Connection`, `Microphone` и `ListeningTrigger`.

### <a name="metric-connection"></a>Метрика `Connection`

Метрика `Connection` указывает сведения о попытках подключения клиента. Метрика должна содержать метки времени, когда соединение WebSocket было запущено и завершено. `Connection`Метрика требуется*только для первого цикла соединения*. В последующие циклы не требуются включать эту информацию. Если клиент делает несколько попыток подключения до установления соединения, необходимо включить информацию о *всех* попытках подключения. Дополнительные сведения см. в разделе [Телеметрия сбоя подключения](#connection-failure-telemetry).

| Поле | ОПИСАНИЕ | Использование |
| ----- | ----------- | ----- |
| ИМЯ | `Connection` | Обязательно |
| Идентификатор | Значение идентификатора соединения, использованное в заголовке *X-ConnectionId* для этого запроса на подключение. | Обязательно |
| Начало | Время, когда клиент отправил запрос на соединение. | Обязательно |
| End | Время, когда клиент получил уведомление о том, что соединение было успешно установлено или, в случае ошибок, отклонено, отказано или не выполнено | Обязательно |
| Ошибка | Описание ошибки, которая произошла, если таковая имеется. Если соединение было успешным, клиенты должны опустить это поле. Максимальная длина этого поля — 50 символов. | Требуется при ошибке; в противном случае опускается. |

Описание ошибки должно быть не длиннее 50 символов и в идеале должно быть одним из значений, перечисленных в следующей таблице. Если условие ошибки не соответствует одному из этих значений, клиенты могут использовать сжатое описание условия, используя [CamelCasing](https://en.wikipedia.org/wiki/Camel_case) без пробела. Возможность отправки сообщения *телеметрии* требует подключения к службе, поэтому в сообщении *телеметрии* могут быть указаны только временные ошибки. Условия ошибки, которые *навсегда* блокируют возможность клиента установить соединение со службой, не позволяют клиенту отправлять какое-либо сообщение службе, включая сообщения *телеметрии*.

| Ошибка | Использование |
| ----- | ----- |
| DNSfailure | Клиент не смог подключиться к службе из-за сбоя DNS в сетевом стеке. |
| NoNetwork | Клиент попытался подключиться, но сетевой стек сообщил, что не была доступна ни одна физическая сеть. |
| NoAuthorization | Не удалось подключиться к клиенту при попытке получить маркер авторизации для подключения. |
| NoResources | При попытке установить соединение клиент исчерпал какой-то локальный ресурс (например, память). |
| Запрещено | Клиент не смог подключиться к службе, потому что служба вернула код состояния HTTP `403 Forbidden` в запросе обновления WebSocket. |
| Не авторизовано | Клиент не смог подключиться к службе, потому что служба вернула код состояния HTTP `401 Unauthorized` в запросе обновления WebSocket. |
| BadRequest | Клиент не смог подключиться к службе, потому что служба вернула код состояния HTTP `400 Bad Request` в запросе обновления WebSocket. |
| ServerUnavailable | Клиент не смог подключиться к службе, потому что служба вернула код состояния HTTP `503 Server Unavailable` в запросе обновления WebSocket. |
| ServerError | Клиент не смог подключиться к службе, потому что служба вернула код состояния внутренней ошибки `HTTP 500` в запросе обновления WebSocket. |
| Время ожидания | Запрос соединения клиента истек без ответа от службы. Поле *End* содержит значение времени, в течение которого клиент превысил время ожидания подключения и прекратил ожидать его. |
| ClientError | Клиент завершил соединение из-за внутренней ошибки клиента. | 

### <a name="metric-microphone"></a>Метрика `Microphone`

Метрика `Microphone` требуется для всех речевых циклов. Эта метрика измеряет время в клиенте, в течение которого входные аудиоданные активно используются для запроса речи.

Используйте следующие примеры в качестве руководства для записи значений времени *Start* для метрики `Microphone` в своем клиентском приложении:

* Клиентское приложение требует, чтобы пользователь нажимал физическую кнопку для включения микрофона. После нажатия кнопки клиентское приложение считывает данные с микрофона и отправляет его в службу распознавания речи. Значение *Start* для метрики `Microphone` записывает время после нажатия кнопки, когда микрофон активирован и готов к получению данных. Значение *End* для метрики `Microphone` записывает время, когда клиентское приложение прекратило передачу звука в службу, после того как оно получило сообщение `speech.endDetected` от службы.

* Клиентское приложение использует корректировщик ключевых слов, который "всегда" выполняет прослушивание. Только после того как корректировщик ключевых слов обнаруживает произносимую триггерную фразу, клиентское приложение получает входной сигнал от микрофона и отправляет его в службу распознавания речи. Значение *Start* для метрики `Microphone` записывает время, когда корректировщик ключевых слов уведомляет клиента начать использовать входные данные с микрофона. Значение *End* для метрики `Microphone` записывает время, когда клиентское приложение прекратило передачу звука в службу, после того как оно получило сообщение `speech.endDetected` от службы.

* Клиентское приложение имеет доступ к постоянному аудиопотоку и выполняет обнаружение тишины или речи в этом потоке в *модуле обнаружения речи*. Значение *Start* для метрики `Microphone` записывает время, когда *модуль обнаружения речи* уведомляет клиента начать использовать входные данные из аудиопотока. Значение *End* для метрики `Microphone` записывает время, когда клиентское приложение прекратило передачу звука в службу, после того как оно получило сообщение `speech.endDetected` от службы.

* Клиентское приложение обрабатывает второй цикл многократного запроса и сообщается ответным сообщением службы, чтобы включить микрофон для получения входных данных для второго цикла. Значение *Start* для метрики `Microphone` записывает время, когда клиентское приложение включает микрофон и начинает использовать входные данные из этого источника звука. Значение *End* для метрики `Microphone` записывает время, когда клиентское приложение прекратило передачу звука в службу, после того как оно получило сообщение `speech.endDetected` от службы.

Значение времени *End* для метрики `Microphone` записывает время, когда клиентское приложение прекратило потоковую передачу входных аудиоданных. В большинстве случаев это событие происходит вскоре после того, как клиент получил сообщение `speech.endDetected` из службы. Клиентские приложения могут убедиться, что они надлежащим образом соответствуют протоколу, гарантируя, что значение времени *End* для метрики `Microphone` более позднее, чем значение времени приема для сообщения `speech.endDetected`. Так как обычно между окончанием одного цикла и началом следующего существует задержка, клиенты могут проверять соответствие протоколу, гарантируя, что значение времени *Start* метрики `Microphone` для любого последующего цикла правильно записывает время, когда клиент *начал работу*, используя микрофон, чтобы передать аудиоданные в службу.

| Поле | ОПИСАНИЕ | Использование |
| ----- | ----------- | ----- |
| ИМЯ | Микрофон | Обязательно |
| Начало | Время, когда клиент начал использовать аудиоданные с микрофона или другой аудиопоток или получил триггер от корректировщика ключевых слов | Обязательно |
| End | Время, когда клиент прекратил использование микрофона или аудиопотока | Обязательно |
| Ошибка | Описание ошибки, которая произошла, если таковая имеется. Если операции с микрофоном были успешными, клиенты должны пропустить это поле. Максимальная длина этого поля — 50 символов. | Требуется при ошибке; в противном случае опускается. |

### <a name="metric-listeningtrigger"></a>Метрика `ListeningTrigger`
Метрика `ListeningTrigger` измеряет время, когда пользователь выполняет действие, которое инициирует ввод речи. Метрика `ListeningTrigger` не является обязательной, но клиентам, которые могут предоставить ее, рекомендуется сделать это.

Используйте следующие примеры в качестве руководства для записи значений времени *Start* и *End* для метрики `ListeningTrigger` в вашем клиентском приложении:

* Клиентское приложение требует, чтобы пользователь нажимал физическую кнопку для включения микрофона. Значение *Start* для этой метрики записывает время нажатия кнопки. Значение *End* записывает время окончания нажатия кнопки.

* Клиентское приложение использует корректировщик ключевых слов, который "всегда" выполняет прослушивание. После того как корректировщик ключевых слов обнаруживает произносимую триггерную фразу, клиентское приложение получает входной сигнал от микрофона и отправляет его в службу распознавания речи. Значение *Start* для этой метрики записывает время, когда корректировщик ключевых слов получил аудиоданные, которые затем были определены как триггерная фраза. Значение *End* записывает время, когда пользователь произнес последнее слово триггерной фразы.

* Клиентское приложение имеет доступ к постоянному аудиопотоку и выполняет обнаружение тишины или речи в этом потоке в *модуле обнаружения речи*. Значение *Start* для этой метрики записывает время, в течение которого *модуль распознавания речи* получил звук, который затем был распознан как речь. Значение *End* записывает время, когда *модуль распознавания речи* обнаружил речь.

* Клиентское приложение обрабатывает второй цикл многократного запроса и сообщается ответным сообщением службы, чтобы включить микрофон для получения входных данных для второго цикла. Клиентское приложение *не* должно включать метрику `ListeningTrigger` для этого цикла.

| Поле | ОПИСАНИЕ | Использование |
| ----- | ----------- | ----- |
| ИМЯ | ListeningTrigger | Необязательно |
| Начало | Время запуска триггера прослушивателя | Обязательно |
| End | Время окончания работы триггера прослушивателя | Обязательно |
| Ошибка | Описание ошибки, которая произошла, если таковая имеется. Если триггер сработал успешно, клиенты должны опустить это поле. Максимальная длина этого поля — 50 символов. | Требуется при ошибке; в противном случае опускается. |

#### <a name="sample-message"></a>Пример сообщения

В следующем примере показано сообщение телеметрии с частями ReceivedMessages и Metrics:

```HTML
Path: telemetry
Content-Type: application/json; charset=utf-8
X-RequestId: 123e4567e89b12d3a456426655440000
X-Timestamp: 2016-08-16T15:03:54.183Z

{
  "ReceivedMessages": [
    { "speech.hypothesis": [ "2016-08-16T15:03:48.171Z", "2016-08-16T15:03:48.331Z", "2016-08-16T15:03:48.881Z" ] },
    { "speech.endDetected": "2016-08-16T15:03:49.721Z" },
    { "speech.phrase": "2016-08-16T15:03:50.001Z" },
    { "turn.end": "2016-08-16T15:03:51.021Z" }
  ],
  "Metrics": [
    {
      "Name": "Connection",
      "Id": "A140CAF92F71469FA41C72C7B5849253",
      "Start": "2016-08-16T15:03:47.921Z",
      "End": "2016-08-16T15:03:48.000Z",
    },
    {
      "Name": "ListeningTrigger",
      "Start": "2016-08-16T15:03:48.776Z",
      "End": "2016-08-16T15:03:48.777Z",
    },
    {
      "Name": "Microphone",
      "Start": "2016-08-16T15:03:47.921Z",
      "End": "2016-08-16T15:03:51.921Z",
    },
  ],
}
```

## <a name="error-handling"></a>Обработка ошибок

В этом разделе описываются типы сообщений об ошибках и условия, которые должно обработать ваше приложение.

### <a name="http-status-codes"></a>Коды состояния HTTP

Во время запроса обновления WebSocket служба распознавания речи может возвращать любой из стандартных кодов состояний HTTP, например `400 Bad Request` и т. д. Ваше приложение должно правильно обрабатывать эти условия ошибки.

#### <a name="authorization-errors"></a>Ошибки авторизации

Если во время обновления WebSocket предоставляется некорректная авторизация, служба возвращает код состояния HTTP `403 Forbidden`. Условия, которые могут вызвать этот код ошибки, следующие:

* Отсутствие заголовка *авторизации*.

* Недопустимый маркер авторизации.

* Маркер авторизации с истекшим сроком действия.

Сообщение об ошибке `403 Forbidden` не указывает на проблему в службе распознавания речи. Это сообщение об ошибке указывает на проблему с клиентским приложением.

### <a name="protocol-violation-errors"></a>Ошибки нарушения протокола

Если служба обнаруживает любые нарушения протокола клиентом, служба завершает соединение WebSocket после возврата *кода состояния* и *причины* для завершения. Клиентские приложения могут использовать эту информацию для устранения неполадок и нарушений.

#### <a name="incorrect-message-format"></a>Неверный формат сообщения

Если клиент отправляет службе текстовое или двоичное сообщение, не закодированное в правильном формате, указанном в этой спецификации, служба прерывает соединение с кодом состояния *1007 — неверные полезные данные*. 

Служба возвращает этот код состояния по целому ряду причин, как показано в следующих примерах:

* "Неверный формат сообщения. Двоичное сообщение имеет недопустимый префикс размера заголовка." Клиент отправил двоичное сообщение с недопустимым префиксом размера заголовка.

* "Неверный формат сообщения. Двоичное сообщение имеет недопустимый размер заголовка." Клиент отправил двоичное сообщение с указанием недопустимого размера заголовка.

* "Неверный формат сообщения. Расшифровка двоичных заголовков сообщений в UTF-8 не удалась." Клиент отправил двоичное сообщение, содержащее заголовки в неправильной кодировке UTF-8.

* "Неверный формат сообщения. В текстовом сообщении нет данных." Клиент отправил текстовое сообщение, в котором нет данных текста.

* "Неверный формат сообщения. Расшифровка текстового сообщения в UTF-8 не удалась." Клиент отправил текстовое сообщение, которое неправильно кодировалось в UTF-8.

* "Неверный формат сообщения. В текстовом сообщении нет разделителя заголовка." Клиент отправил текстовое сообщение, которое не содержало разделитель заголовка или использовало неправильный разделитель заголовков.

#### <a name="missing-or-empty-headers"></a>Отсутствующие или пустые заголовки

Если клиент отправляет сообщение без требуемых заголовков *X-RequestId* или *Path*, служба завершает соединение с кодом состояния *1002 — ошибка протокола*. Появится сообщение "Заголовок пуст или отсутствует. {Имя заголовка}."

#### <a name="requestid-values"></a>Значения RequestID

Если клиент отправляет сообщение с заголовком *X-RequestId* в неправильном формате, служба прерывает соединение и возвращает состояние *1002 — ошибка протокола*. Сообщение "Недопустимый запрос. Значение заголовка X-RequestId не указано в формате UUID без тире."

#### <a name="audio-encoding-errors"></a>Ошибки кодирования аудио

Если клиент отправляет звуковой блок, который инициирует цикл, а формат аудио или кодировка не соответствует требуемой спецификации, служба прерывает соединение и возвращает код состояния *1007 — неверные полезные данные*. Сообщение указывает на источник ошибки кодирования формата.

#### <a name="requestid-reuse"></a>Повторное использование RequestId

По завершении цикла, если клиент отправляет сообщение, которое повторно использует идентификатор запроса из этого цикла, служба прерывает соединение и возвращает код состояния *1002 — ошибка протокола*. Сообщение "Недопустимый запрос. Повторное использование идентификаторов запросов не допускается."

## <a name="connection-failure-telemetry"></a>Телеметрия сбоя подключения

Чтобы обеспечить лучшее взаимодействие пользователя, клиенты должны сообщать службе распознавания речи метки времени для важных контрольных точек в подключении с помощью сообщения *телеметрии*. Не менее важно, чтобы клиенты сообщали службе о подключениях, которые были предприняты, но не удались.

Для каждой неудачной попытки подключения клиенты создают сообщение *телеметрии* с уникальным значением заголовка *X-RequestId*. Так как клиент не смог установить подключение, поле *ReceivedMessages* в тексте JSON может быть опущено. Включена только запись `Connection` в поле *Metrics*. Эта запись содержит метки времени начала и окончания, а также условие обнаруженной ошибки.

### <a name="connection-retries-in-telemetry"></a>Повторные попытки подключения в телеметрии

Клиенты должны различать *повторные попытки* от *попыток множественных подключений* с помощью события, которое запускает попытку подключения. Попытки подключения, которые выполняются программно без какого-либо ввода пользователя, являются повторными. Несколько попыток подключения, которые выполняются в ответ на ввод пользователя, — это попытки множественных подключений. Клиенты дают каждой попытке соединения, инициированной пользователем, уникальное сообщение *X-RequestId* и *телеметрии*. Клиенты повторно используют *X-RequestId* для программных повторных попыток. Если для одного подключения было сделано несколько попыток, каждая попытка повторного подключения включается как запись `Connection` в сообщение *телеметрии*.

Например, предположим, что пользователь говорит ключевое слово-триггер, чтобы начать соединение, и первая попытка подключения завершилась неудачей из-за ошибок DNS. Однако вторая попытка, сделанная программным путем клиентом, удается. Так как клиент повторил подключение, не требуя дополнительного ввода от пользователя, клиент использует одно сообщение *телеметрии* с несколькими записями `Connection` для описания соединения.

Далее, предположим, что пользователь говорит ключевое слово-триггер, чтобы начать соединение, и эта попытка подключения завершилась неудачей после трех повторных попыток. Затем клиент перестает пытаться подключиться к службе и сообщает пользователю, что что-то пошло не так. Затем пользователь снова вызывает ключевое слово-триггер. На этот раз предположим, что клиент подключается к службе. После подключения клиент немедленно отправляет сообщение *телеметрии* в службу, которое содержит три записи `Connection`, описывающие сбои подключения. После получения сообщения `turn.end` клиент отправляет другое *сообщение телеметрии*, которое описывает успешное соединение.

## <a name="error-message-reference"></a>Справочные материалы по сообщениям ошибок

### <a name="http-status-codes"></a>Коды состояния HTTP

| HTTP status code (Код состояния HTTP) | ОПИСАНИЕ | Устранение неполадок |
| - | - | - |
| 400 — недопустимый запрос | Клиент отправил запрос на соединение с WebSocket, который был неверным. | Убедитесь, что вы предоставили все необходимые параметры и заголовки HTTP и правильные значения. |
| 401 — недостаточно прав | Клиент не включил требуемую информацию авторизации. | Убедитесь, что вы отправляете заголовок *авторизации* в соединении WebSocket. |
| 403. Запрещено | Клиент отправил сведения об авторизации, но они были недействительны. | Убедитесь, что вы не отправляете значение с истекшим сроком годности или недопустимое значение в заголовке *авторизации*. |
| 404 — не найдено | Клиент попытался получить доступ к URL-адресу, который не поддерживается. | Убедитесь, что вы используете правильный URL-адрес для подключения к WebSocket. |
| 500 — ошибка сервера | Служба обнаружила внутреннюю ошибку и не может выполнить запрос. | В большинстве случаев эта ошибка является временной. Повторите запрос. |
| 503 — Служба недоступна | Служба была недоступна для обработки запроса. | В большинстве случаев эта ошибка является временной. Повторите запрос. |

### <a name="websocket-error-codes"></a>Коды ошибок WebSocket

| Код WebSocketsStatus | ОПИСАНИЕ | Устранение неполадок |
| - | - | - |
| 1000 — нормальное закрытие | Служба прервала соединение WebSocket без ошибок. | Если закрытие WebSocket было неожиданным, перечитайте документацию, чтобы убедиться, что вы понимаете, как и когда служба может завершить соединение WebSocket. |
| 1002 — ошибка протокола | Клиент не соответствует требованиям протокола. | Убедитесь, что вы понимаете документацию по протоколу и требования. Прочтите предыдущую документацию о причинах ошибок, чтобы убедиться, что вы не нарушаете требования протокола. |
| 1007 — недопустимые полезные данные | Клиент отправил недопустимые полезные данные в сообщении протокола. | Проверьте последнее сообщение, отправленное в службу, на наличие ошибок. Прочтите предыдущую документацию об ошибках полезных данных. |
| 1011 — ошибка сервера | Служба обнаружила внутреннюю ошибку и не может выполнить запрос. | В большинстве случаев эта ошибка является временной. Повторите запрос. |

## <a name="related-topics"></a>Связанные разделы

Дополнительные сведения см. в статье [о пакете SDK](https://github.com/Azure-Samples/SpeechToText-WebSockets-Javascript), который является реализацией протокола службы распознавания речи на основе WebSocket.
