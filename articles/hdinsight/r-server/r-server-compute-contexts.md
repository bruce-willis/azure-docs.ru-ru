---
title: Параметры контекста вычислений для Служб машинного обучения в HDInsight в Azure
description: Сведения о различных параметрах контекста вычислений, доступных для пользователей Служб машинного обучения служб машинного обучения в HDInsight.
services: hdinsight
ms.service: hdinsight
author: jasonwhowell
ms.author: jasonh
ms.reviewer: jasonh
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 06/27/2018
ms.openlocfilehash: b956a641c6e6797efde98e7b613e6ce91023fc09
ms.sourcegitcommit: 161d268ae63c7ace3082fc4fad732af61c55c949
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/27/2018
ms.locfileid: "43042063"
---
# <a name="compute-context-options-for-ml-services-on-hdinsight"></a>Параметры контекста вычислений для Служб машинного обучения в HDInsight

Службы машинного обучения в Azure HDInsight управляют выполнением вызовов, задавая контекст вычисления. В этой статье приведены параметры, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight.

Для подключения к кластеру и выполнения скриптов на языке R удобно использовать граничный узел кластеров. На граничном узле вы можете выполнять распараллеленные распределенные функции RevoScaleR на ядрах сервера граничного узла. Кроме того, вы можете выполнять эти функции на узлах кластера с помощью контекста вычислений Hadoop Map Reduce или Spark RevoScaleR.

## <a name="ml-services-on-azure-hdinsight"></a>Службы машинного обучения в Azure HDInsight
[Службы машинного обучения в Azure HDInsight](r-server-overview.md) предоставляют новейшие возможности для анализа на основе R. Это решение может использовать данные, хранящиеся в контейнере HDFS, размещенном в учетной записи хранения [BLOB-объектов Azure](../../storage/common/storage-introduction.md "хранилище BLOB-объектов Azure"), Data Lake Store или локальной файловой системе Linux. Так как Службы машинного обучения основаны на R с открытым кодом, вы сможете использовать в своих приложениях на базе R любые из более чем 8000 пакетов R с открытым кодом. Также вы можете использовать подпрограммы [RevoScaleR](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/revoscaler) — пакета аналитики больших данных от корпорации Майкрософт, который предоставляется вместе со Службами машинного обучения.  

## <a name="compute-contexts-for-an-edge-node"></a>Контексты вычислений для граничного узла
Как правило, скрипт R, выполняемый в Службах машинного обучения на граничном узле, выполняется в интерпретаторе R на этом узле. Исключением являются те действия, которые вызывают функцию RevoScaleR. Вызовы RevoScaleR будут осуществляться в среде вычислений с учетом настройки контекста вычислений RevoScaleR.  При выполнении скрипта R из граничного узла возможны следующие значения контекста вычислений:

- локальный последовательный (*local*);
- локальный параллельный (*localpar*);
- Map Reduce
- Spark

Значения *local* и *localpar* отличаются только способом выполнения вызовов **rxExec**. Они оба выполняют другие вызовы функций RX параллельно по всем доступным ядрам, если только не указаны другие действия посредством параметра RevoScaleR **numCoresToUse**, например `rxOptions(numCoresToUse=6)`. Параметры параллельного выполнения обеспечивают оптимальную производительность.

В таблице ниже приведена сводка различных параметров контекста вычислений, определяющих способ выполнения вызовов.

| Контекст вычислений  | Метод настройки                      | Контекст выполнения                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| Локальный последовательный | rxSetComputeContext('local')    | Распараллеленное выполнение во всех ядрах сервера граничного узла, за исключением вызовов rxExec, которые выполняются последовательно. |
| Локальный параллельный   | rxSetComputeContext('localpar') | Распараллеленное выполнение во всех ядрах сервера граничного узла. |
| Spark            | RxSpark()                       | Распараллеленное распределенное выполнение с использованием Spark во всех узлах кластера HDI |
| Map Reduce       | RxHadoopMR()                    | Распараллеленное распределенное выполнение с использованием Map Reduce во всех узлах кластера HDI |

## <a name="guidelines-for-deciding-on-a-compute-context"></a>Рекомендации по выбору контекста вычислений

Выбор варианта распараллеленного выполнения зависит от характера задач анализа, а также размера и местонахождения данных. Простого правила для выбора контекста вычислений нет. Однако есть некоторые базовые принципы, которые помогут вам определиться или хотя бы сузить выбор еще до запуска теста производительности. К ним относятся следующие:

- Локальная файловая система Linux работает быстрее, чем HDFS.
- Повторный анализ выполняется быстрее для данных в локальной среде, особенно в формате XDF.
- Из текстовых источников данных желательно передавать небольшие объемы данных. Если данные имеют большой объем, преобразуйте их в формат XDF перед анализом.
- При копировании или потоковой передаче на граничный узел больших объемов данных для анализа нагрузка быстро становится запредельной.
- Spark работает быстрее, чем MapReduce для анализа в Hadoop.

С учетом этих принципов в следующем разделе приведены некоторые общие правила выбора контекста вычислений.

### <a name="local"></a>Local
* Если нужно проанализировать данные небольшого объема и не требуется повторный анализ, их следует направить потоком прямо в подпрограмму анализа и использовать контекст *local* или *localpar*.
* Если нужно проанализировать данные небольшого или среднего объема, для которых потребуется повторный анализ, скопируйте их в локальную файловую систему, импортируйте в XDF-формат и проанализируйте в контексте *local* или *localpar*.

### <a name="hadoop-spark"></a>Hadoop Spark
* Если нужно проанализировать большой объем данных, импортируйте их в Spark DataFrame с помощью **RxHiveData** или **RxParquetData** либо в XDF-файл в файловой системе HDFS (при наличии достаточного пространства для хранения) и проанализируйте эти данные в контексте вычислений Spark.

### <a name="hadoop-map-reduce"></a>Hadoop Map Reduce
* Используйте контекст вычислений Map Reduce только для проблем, которые не решаются с использованием контекста вычислений Spark из-за снижения производительности.  

## <a name="inline-help-on-rxsetcomputecontext"></a>Встроенная справка по rxSetComputeContext
Чтобы получить дополнительные сведения по контекстам вычислений RevoScaleR с соответствующими примерами, воспользуйтесь встроенной справкой в консоли R с помощью метода rxSetComputeContext, например:

    > ?rxSetComputeContext

Также см. [обзор распределенных вычислений](https://docs.microsoft.com/machine-learning-server/r/how-to-revoscaler-distributed-computing) в [документации Machine Learning Server](https://docs.microsoft.com/machine-learning-server/).

## <a name="next-steps"></a>Дополнительная информация
В этой статье вы ознакомились с параметрами, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight. Дополнительные сведения об использовании Служб машинного обучения в кластерах HDInsight см. в следующих статьях:

* [Основные сведения об R Server и возможностях открытого кода R в HDInsight](r-server-overview.md)
* [Начало работы со службами машинного обучения в Azure HDInsight](r-server-get-started.md)
* [Решения службы хранилища Azure для R Server в Azure HDInsight](r-server-storage.md)

