---
title: Перенос данных в учетную запись API Cassandra в Azure Cosmos DB
description: Сведения об использовании команды CQL Copy и Spark для копирования данных из Apache Cassandra в API Cassandra для Azure Cosmos DB.
services: cosmos-db
author: kanshiG
ms.service: cosmos-db
ms.component: cosmosdb-cassandra
ms.author: govindk
ms.topic: tutorial
ms.date: 09/24/2018
ms.reviewer: sngun
ms.openlocfilehash: 0bf5e47513ded4b2c65e7291db497e53a42776a8
ms.sourcegitcommit: 32d218f5bd74f1cd106f4248115985df631d0a8c
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/24/2018
ms.locfileid: "46976182"
---
# <a name="migrate-your-data-to-azure-cosmos-db-cassandra-api-account"></a>Перенос данных в учетную запись API Cassandra в Azure Cosmos DB

Это руководство содержит инструкции по переносу данных Apache Cassandra в API Cassandra для Azure Cosmos DB. 

В рамках этого руководства рассматриваются следующие задачи:

> [!div class="checklist"]
> * Планирование миграции
> * Предварительные требования для миграции
> * Перенос данных с помощью команды cqlsh COPY
> * Перенос данных с помощью Spark 

## <a name="plan-for-migration"></a>Планирование миграции

Перед миграцией данных в API Cassandra для Azure Cosmos DB следует оценить потребности пропускной способности вашей рабочей нагрузки. Как правило, рекомендуется начинать со средней пропускной способности, требуемой для операций CRUD, а затем включить дополнительную пропускную способность, необходимую для операций извлечения, преобразования и загрузки (ETL) или операций, для которых характерны резкие скачки. Для планирования миграции необходимо знать следующее. 

* **Текущий или предполагаемый размер данных**. Определяет минимальные требования к размеру базы данных и пропускной способности. Если вы оцениваете размер данных для нового приложения, можно предположить, что данные равномерно распределены по строкам, и получить примерное значение путем умножения на размер данных. 

* **Требуемая пропускная способность**. Приблизительная пропускная способность для операций чтения (запрос, получение) и записи (изменение, удаление, вставка). Это значение необходимо для вычисления требуемого количества единиц, а также размера данных в устойчивом состоянии.  

* **Получите схему**. Подключитесь к существующему кластеру Cassandra с помощью cqlsh и экспортируйте схему из Cassandra: 

  ```bash
  cqlsh [IP] "-e DESC SCHEMA" > orig_schema.cql
  ```

Определив требования существующей рабочей нагрузки, необходимо создать учетную запись Azure Cosmos DB, базу данных и контейнеры в соответствии с полученными требованиями к пропускной способности.  

* **Определите стоимость ЕЗ для операции**. Количество ЕЗ можно определить с помощью пакета SDK для API Cassandra для Azure Cosmos DB. В этом примере мы используем для оценки затрат версию .NET.

  ```csharp
  var tableInsertStatement = table.Insert(sampleEntity);
  var insertResult = await tableInsertStatement.ExecuteAsync();

  foreach (string key in insertResult.Info.IncomingPayload)
    {
       byte[] valueInBytes = customPayload[key];
       string value = Encoding.UTF8.GetString(valueInBytes);
       Console.WriteLine($"CustomPayload:  {key}: {value}");
    }
  ```

* **Выделите требуемую пропускную способность**. Azure Cosmos DB поддерживает автоматическое масштабирование хранилища и пропускной способности по мере роста требований. Вы можете оценить требуемую вам пропускную способность с помощью [калькулятора единиц запроса Azure Cosmos DB](https://www.documentdb.com/capacityplanner). 

## <a name="prerequisites-for-migration"></a>Предварительные требования для миграции

* **Создайте таблицы в учетной записи API Cassandra для Azure Cosmos DB**. Прежде чем начать миграцию данных, предварительно создайте все таблицы с помощью портала Azure или cqlsh.

* **Увеличьте пропускную способность**. Продолжительность миграции данных зависит от пропускной способности, которую вы предоставите для таблиц в Azure Cosmos DB. Увеличьте пропускную способность на время выполнения миграции. Более высокая пропускная способность позволяет избежать ограничения скорости и выполнить перенос быстрее. После переноса уменьшите пропускную способность для экономии расходов. Дополнительные сведения об увеличении пропускной способности см. в статье, посвященной [настройке пропускной способности](set-throughput.md) для контейнеров Azure Cosmos DB. Также рекомендуется использовать учетную запись Azure Cosmos DB из того же региона, где находится база данных-источник. 

* **Включите SSL**. В Azure Cosmos DB реализуются строгие требования и стандарты безопасности. Обязательно включите SSL при взаимодействии с учетной записью. При использовании CQL с SSH у вас есть возможность предоставить сведения SSL.

## <a name="options-to-migrate-data"></a>Варианты миграции данных

Вы можете переместить данные из существующих рабочих нагрузок Cassandra в Azure Cosmos DB следующим образом:

* [с помощью команды cqlsh COPY](#using-cqlsh-copy-command);  
* [с помощью Spark](#using-spark). 

## <a name="migrate-data-using-cqlsh-copy-command"></a>Перенос данных с помощью команды cqlsh COPY

[Команда CQL COPY](http://cassandra.apache.org/doc/latest/tools/cqlsh.html#cqlsh) используется для копирования локальных данных в учетную запись API Cassandra для Azure Cosmos DB. Выполните указанные ниже действия, чтобы копировать данные.

1. Получение сведений о строке подключения для учетной записи API Cassandra

   * Войдите на [портал Azure](https://portal.azure.com) и перейдите в учетную запись Azure Cosmos DB.

   * Откройте область **Строка подключения**, которая содержит все сведения, необходимые для подключения к учетной записи API Cassandra из cqlsh.

2. Войдите в cqhsh, используя полученные на портале сведения о подключении.

3. Используйте команду CQL COPY, чтобы скопировать локальные данные в учетную запись API Cassandra.

   ```bash
   COPY exampleks.tablename FROM filefolderx/*.csv 
   ```

## <a name="migrate-data-using-spark"></a>Перенос данных с помощью Spark 

Следуйте инструкциям ниже, чтобы перенести данные в API Cassandra для Azure Cosmos DB с помощью Spark.

- Подготовка кластера [Azure Databricks](cassandra-spark-databricks.md) или [HDInsight](cassandra-spark-hdinsight.md) 

- Перемещение данных в целевую конечную точку API Cassandra с помощью [табличной операции копирования](cassandra-spark-table-copy-ops.md) 

Перенос данных с помощью заданий Spark рекомендуется, если у вас есть данные, хранимые в существующем кластере в виртуальных машинах Azure или в любом другом облаке. Для этого следует настроить Spark в качестве промежуточного звена для однократного или регулярного приема данных. Вы можете ускорить миграцию с помощью подключений ExpressRoute между локальной сетью и Azure. 

## <a name="next-steps"></a>Дополнительная информация

В этом руководстве вы узнали, как выполнить миграцию данных в учетную запись API Cassandra для Azure Cosmos DB. Теперь можно перейти к разделу основных понятий, чтобы получить дополнительные сведения о службе Azure Cosmos DB. 

> [!div class="nextstepaction"]
> [Настраиваемые уровни согласованности данных в Azure Cosmos DB](../cosmos-db/consistency-levels.md)


